{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a7ea14",
   "metadata": {},
   "source": [
    "# Linear Regression: Predicting total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07fbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859ce847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 03:09:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TLC Linear Regression\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cdd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path lists\n",
    "fact_trip = \"hdfs://10.128.0.59:8020/data_warehouse/fact_trip\"\n",
    "dim_datetime = \"hdfs://10.128.0.59:8020/data_warehouse/dim_datetime\"\n",
    "\n",
    "output = \"uber-analysis-439804.query_result.model_evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9b094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: long (nullable = true)\n",
      " |-- vendor_id: long (nullable = true)\n",
      " |-- pu_location_id: long (nullable = true)\n",
      " |-- do_location_id: long (nullable = true)\n",
      " |-- ratecode_id: long (nullable = true)\n",
      " |-- payment_id: long (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pick_hour: double (nullable = true)\n",
      " |-- pick_weekday_id: integer (nullable = true)\n",
      " |-- drop_hour: double (nullable = true)\n",
      " |-- drop_weekday_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", fact_trip) \\\n",
    "    .load()\n",
    "\n",
    "df_datetime = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", dim_datetime) \\\n",
    "    .load() \\\n",
    "    .filter(col(\"pick_year\") == 2024) \\\n",
    "    .select(\n",
    "        col(\"datetime_id\"),\n",
    "        col(\"pick_hour\"),\n",
    "        col(\"pick_weekday_id\"),\n",
    "        col(\"drop_hour\"),\n",
    "        col(\"drop_weekday_id\")\n",
    "    )\n",
    "\n",
    "df_joined = df_fact \\\n",
    "    .join(df_datetime,\n",
    "          df_fact.datetimestamp_id == df_datetime.datetime_id, \"inner\") \\\n",
    "    .drop(col(\"datetimestamp_id\"), col(\"datetime_id\"))\n",
    "\n",
    "df_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbaf1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    \"vendor_id\",\n",
    "    \"pu_location_id\",\n",
    "    \"do_location_id\",\n",
    "    \"ratecode_id\",\n",
    "    \"payment_id\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"pick_hour\",\n",
    "    \"pick_weekday_id\",\n",
    "    \"drop_hour\",\n",
    "    \"drop_weekday_id\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=selected_columns,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data_transformed = assembler.transform(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56d4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_data, test_data = data_transformed.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada455bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"total_amount\",\n",
    "    regParam=0.01\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trained_model = lr_model.fit(train_data)\n",
    "\n",
    "# Testing\n",
    "predictions = trained_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e34bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "r2 = r2_evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d74ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+------------------+\n",
      "|             name|             rmse|               mae|                r2|\n",
      "+-----------------+-----------------+------------------+------------------+\n",
      "|Linear Regression|0.502891116917058|0.2197194188491359|0.9995676032268148|\n",
      "+-----------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Store in BigQuery\n",
    "evaluation_data = spark.createDataFrame([\n",
    "    Row(name=\"Linear Regression\", rmse=rmse, mae=mae, r2=r2)\n",
    "])\n",
    "\n",
    "evaluation_data.show()\n",
    "\n",
    "evaluation_data.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"table\", output) \\\n",
    "    .option(\"temporaryGcsBucket\", \"uber-pyspark-jobs/temp\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c81c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b5dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
