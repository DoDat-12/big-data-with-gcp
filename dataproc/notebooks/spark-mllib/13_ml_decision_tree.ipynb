{"cells": [{"cell_type": "markdown", "id": "d448b1b7", "metadata": {}, "source": "# Decision Tree: Predicting Total Amount"}, {"cell_type": "code", "execution_count": 1, "id": "4f367696", "metadata": {}, "outputs": [], "source": "# Import Libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import DecisionTreeRegressor"}, {"cell_type": "code", "execution_count": 2, "id": "e3c12158", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/30 13:49:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "# Create SparkSession\nspark = SparkSession.builder \\\n    .appName(\"TLC Decision Tree\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "27eb6d51", "metadata": {}, "outputs": [], "source": "# Path lists\nfact_trip = \"hdfs://10.128.0.59:8020/data_warehouse/fact_trip\"\ndim_datetime = \"hdfs://10.128.0.59:8020/data_warehouse/dim_datetime\"\n\noutput = \"uber-analysis-439804.query_result.model_evaluation\""}, {"cell_type": "code", "execution_count": 4, "id": "52547255", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- trip_id: long (nullable = true)\n |-- vendor_id: long (nullable = true)\n |-- pu_location_id: long (nullable = true)\n |-- do_location_id: long (nullable = true)\n |-- ratecode_id: long (nullable = true)\n |-- payment_id: long (nullable = true)\n |-- passenger_count: long (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- pick_hour: double (nullable = true)\n |-- pick_weekday_id: integer (nullable = true)\n |-- drop_hour: double (nullable = true)\n |-- drop_weekday_id: integer (nullable = true)\n\n"}], "source": "df_fact = spark.read \\\n    .format(\"parquet\") \\\n    .option(\"path\", fact_trip) \\\n    .load()\n\ndf_datetime = spark.read \\\n    .format(\"parquet\") \\\n    .option(\"path\", dim_datetime) \\\n    .load() \\\n    .filter(col(\"pick_year\") == 2024) \\\n    .select(\n        col(\"datetime_id\"),\n        col(\"pick_hour\"),\n        col(\"pick_weekday_id\"),\n        col(\"drop_hour\"),\n        col(\"drop_weekday_id\")\n    )\n\ndf_joined = df_fact \\\n    .join(df_datetime,\n          df_fact.datetimestamp_id == df_datetime.datetime_id, \"inner\") \\\n    .drop(col(\"datetimestamp_id\"), col(\"datetime_id\"))\n\ndf_joined.printSchema()"}, {"cell_type": "code", "execution_count": 5, "id": "5ea8b725", "metadata": {}, "outputs": [], "source": "selected_columns = [\n    \"vendor_id\",\n    \"pu_location_id\",\n    \"do_location_id\",\n    \"ratecode_id\",\n    \"payment_id\",\n    \"passenger_count\",\n    \"trip_distance\",\n    \"fare_amount\",\n    \"extra\",\n    \"mta_tax\",\n    \"tip_amount\",\n    \"tolls_amount\",\n    \"pick_hour\",\n    \"pick_weekday_id\",\n    \"drop_hour\",\n    \"drop_weekday_id\"\n]\n\nassembler = VectorAssembler(\n    inputCols=selected_columns,\n    outputCol=\"features\"\n)\n\ndata_transformed = assembler.transform(df_joined)"}, {"cell_type": "code", "execution_count": 6, "id": "38052e9f", "metadata": {}, "outputs": [], "source": "# Split dataset\ntrain_data, test_data = data_transformed.randomSplit([0.8, 0.2])"}, {"cell_type": "code", "execution_count": 8, "id": "7058f858", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "dt_model = DecisionTreeRegressor(\n    featuresCol=\"features\",\n    labelCol=\"total_amount\"\n)\n\ntrained_model = dt_model.fit(train_data)\npredictions = trained_model.transform(test_data)"}, {"cell_type": "code", "execution_count": 9, "id": "cbb32cce", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Evaluation\nrmse_evaluator = RegressionEvaluator(\n    labelCol=\"total_amount\",\n    predictionCol=\"prediction\",\n    metricName=\"rmse\"\n)\n\nmae_evaluator = RegressionEvaluator(\n    labelCol=\"total_amount\",\n    predictionCol=\"prediction\",\n    metricName=\"mae\"\n)\n\nr2_evaluator = RegressionEvaluator(\n    labelCol=\"total_amount\",\n    predictionCol=\"prediction\",\n    metricName=\"r2\"\n)\n\nrmse = rmse_evaluator.evaluate(predictions)\nmae = mae_evaluator.evaluate(predictions)\nr2 = r2_evaluator.evaluate(predictions)"}, {"cell_type": "code", "execution_count": 10, "id": "eee51634", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------+-----------------+------------------+------------------+\n|         name|             rmse|               mae|                r2|\n+-------------+-----------------+------------------+------------------+\n|Decision Tree|5.802650928063011|2.3770243053773097|0.9420649347455645|\n+-------------+-----------------+------------------+------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Store in BigQuery\nevaluation_data = spark.createDataFrame([\n    Row(name=\"Decision Tree\", rmse=rmse, mae=mae, r2=r2)\n])\n\nevaluation_data.show()\n\nevaluation_data.write \\\n    .format(\"bigquery\") \\\n    .option(\"table\", output) \\\n    .option(\"temporaryGcsBucket\", \"uber-pyspark-jobs/temp\") \\\n    .mode(\"append\") \\\n    .save()"}, {"cell_type": "code", "execution_count": 11, "id": "9198a7a9", "metadata": {}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "4d250da2", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}