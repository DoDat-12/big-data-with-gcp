{"cells": [{"cell_type": "code", "execution_count": 1, "id": "8dc73781", "metadata": {}, "outputs": [], "source": "# Import\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *"}, {"cell_type": "code", "execution_count": 2, "id": "67dfa7f2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/25 14:21:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "# Start Spark Session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"General Aggregation Per Year\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "d710d31c", "metadata": {}, "outputs": [], "source": "# Path lists\nzone_lookup = \"hdfs://10.128.0.59:8020/raw_data/updated_zone_lookup.csv\"\nfact_trip = \"hdfs://10.128.0.59:8020/data_warehouse/fact_trip\"\ndim_vendor = \"hdfs://10.128.0.59:8020/data_warehouse/dim_vendor\"\ndim_datetime = \"hdfs://10.128.0.59:8020/data_warehouse/dim_datetime\"\ndim_rate_code = \"hdfs://10.128.0.59:8020/data_warehouse/dim_rate_code\"\ndim_pickup_location = \"hdfs://10.128.0.59:8020/data_warehouse/dim_pickup_location\"\ndim_dropoff_location = \"hdfs://10.128.0.59:8020/data_warehouse/dim_dropoff_location\"\ndim_payment = \"hdfs://10.128.0.59:8020/data_warehouse/dim_payment\"\n\n# uber-analysis-439804.query_result. + the table's name\noutput = \"uber-analysis-439804.query_result.agg_per_year\""}, {"cell_type": "code", "execution_count": 4, "id": "7f2c15fc", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Read data into dataframe\ndf_fact = spark.read \\\n    .format(\"parquet\") \\\n    .option(\"path\", fact_trip) \\\n    .load()\n\ndf_datetime = spark.read \\\n    .format(\"parquet\") \\\n    .option(\"path\", dim_datetime) \\\n    .load() \\\n    .select(\"pick_year\", \"datetime_id\")"}, {"cell_type": "code", "execution_count": 5, "id": "b6156ed8", "metadata": {}, "outputs": [], "source": "# Join\ndf_joined = df_fact.join(df_datetime, \n                         df_fact.datetimestamp_id == df_datetime.datetime_id,\n                        \"inner\")\n\n# Query\ndf_result = df_joined.groupBy(\"pick_year\") \\\n    .agg(\n        count(\"trip_id\").alias(\"total_trips\"),\n        sum(\"passenger_count\").alias(\"total_passengers\"),\n        sum(\"trip_distance\").alias(\"total_distance\"),\n        sum(\"total_amount\").alias(\"total_amount\"),\n        avg(\"passenger_count\").alias(\"average_passengers_per_trip\"),\n        avg(\"trip_distance\").alias(\"average_distance_per_trip\"),\n        avg(\"total_amount\").alias(\"average_amount_per_trip\")) \\\n    .select(\n        col(\"pick_year\").alias(\"year\"),\n        \"total_trips\",\n        \"total_passengers\",\n        \"total_distance\",\n        \"total_amount\",\n        \"average_passengers_per_trip\",\n        \"average_distance_per_trip\",\n        \"average_amount_per_trip\"\n    )\n    \n\n# df_result.show()"}, {"cell_type": "code", "execution_count": 6, "id": "bc2c54b3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Save to BigQuery\ndf_result.write \\\n    .format(\"bigquery\") \\\n    .option(\"table\", output) \\\n    .option(\"temporaryGcsBucket\", \"uber-pyspark-jobs/temp\") \\\n    .mode(\"overwrite\") \\\n    .save()"}, {"cell_type": "code", "execution_count": 7, "id": "051e06ba", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}